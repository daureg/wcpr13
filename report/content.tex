\begin{abstract}
	Summarize problem, method and result in 150 words.
\end{abstract}
\newpage

\section{Introduction}
Human personality can be described in terms of five \emph{traits}\footnote{Although others are listed on
\href{http://en.wikipedia.org/wiki/Trait\_theory\#List\_of\_personality\_traits}{the
relevant Wikipedia page}.}, presented in \autocite{mairesse2007perso} as follow:
\begin{itemize}
\item Extraversion vs. Introversion (sociable, assertive, playful vs. aloof, reserved, shy)
\item Emotional stability vs. Neuroticism (calm, unemotional vs. insecure, anxious)
\item Agreeableness vs. Disagreeable (friendly, cooperative vs. antagonistic, faultfinding)
\item Conscientiousness vs. Unconscientious (self-disciplined, organised vs. inefficient, careless)
\item Openness to experience (intellectual, insightful vs. shallow, unimaginative)
\end{itemize}

In this project, we will consider that each of these dimensions is binary (whereas one may argue that no individual can be perfectly extroverted or introverted) and we will try to classify people in each dimension based on their writing. More specifically, some student were asked to produce a so called \emph{stream of consciousness} essay, meaning that they wrote their current thoughts freely for twenty minutes. \Textcite{pennebaker1999corpus} collected 2468 such essays which account for about 1.6 millions words\footnote{It is surprisingly difficult to come with a precise figure because \emph{word} is loosely defined.}. Furthermore, they labelled this dataset by assessing the personality of each author with a standard questionnaire.

The key idea is that the way we express ourselves (for instance by writing) reflect our personality. In Bayesian terms, we would say that the text is an observed variable which is conditioned by a hidden one, the personality. Naturally, 

Describe the data, the problem and related one (sentiment analysis), the
previous works\cite{mairesse2007perso}, the method that will be used.

\section{Pre processing}
Before doing any Classification, I perform several operations to transform the raw data contained in the file \texttt{essays.csv} into a document-term matrix, which is a more suitable representation.
\begin{itemize}
	\item First, I separate in each line the text itself from the five labels, which pose no difficulties but is mentioned here for the sake of completeness. Another \enquote{easy but annoying} issue was that some characters generate encoding error (which was solved not elegantly by removing them, since there was only a few of them).
	\item I then wondered what to do about numbers not written in full. I changed single digit into equivalent word (as shown in Table \vref{tab:num}) and replace all the other by a single unique token (\texttt{xnumx}).
		\begin{table}[hb]
			\centering
			\begin{tabular}{cccccccccccc}
				\toprule
				& zero & one & two & three & four & five & six & seven & eight & nine &
				\emph{total} \tabularnewline
				\midrule
				raw & \numprint{18} & \numprint{4816} & \numprint{1193} &
				\numprint{518} & \numprint{287} & \numprint{276} & \numprint{126} &
				\numprint{95} & \numprint{64} & \numprint{60} & \numprint{7453}
				\tabularnewline
				converted & \numprint{134} & \numprint{5090} & \numprint{1814} &
				\numprint{1069} & \numprint{737} & \numprint{748} & \numprint{375} &
				\numprint{297} & \numprint{309} & \numprint{262} & \numprint{10835}
				\tabularnewline
				\bottomrule
			\end{tabular}
			\caption{Counts of the ten words representing digit. The first line referred to the raw data, while in the second, single digit number have been converted to the corresponding word. Although it is probably irrelevant, it is amusing to note most people in this informal setting write numbers with digit and not letters, especially if the number is not 1 (and to some extent, 2 and 3).}
			\label{tab:num}
		\end{table}

	 \item To reduce the sparsity of data, I decide to stem all the words, even though is was not such a severe problem because the text are all in American English, which is a rather analytical language. Because I used the python language, I first looked at various algorithms offered by the \gls{nltk} library\autocite{bird2009nltk}. \texttt{nltk.WordNet} is based on the morphy function\footnote{\href{http://wordnet.princeton.edu/man/morphy.7WN.html}{http://wordnet.princeton.edu/man/morphy.7WN.html}} that apply some suffix-suppresion rules before looking up in a database of base forms. In my case, it was rather slow and for some reasons, it only remove plural ending (like \emph{s}) but did nothing about past tense verbs. NLTK also implements Porter\autocite{porter1980algo} and Snowball\autocite{porter2001snowball} algorithms but although it is highly subjective, I found them a bit too \enquote{aggressive}, for instance transforming \emph{was} to \emph{wa}.  Therefore I finally choose hunspell\footnote{\href{http://hunspell.sourceforge.net/}{http://hunspell.sourceforge.net/}}, which nonetheless comes with its own issues such as totally discarding punctuation, segmenting differently (for instance, \emph{mid-day} to \emph{mid} and \emph{day}) and generating some irrelevant alternatives (\emph{thing} is transformed into \emph{thing} but also into \emph{the+ING}) or missing one (\emph{woke} was not changed to \emph{wake}). For the last two problems, \gls{pos} tagging could have helped but because of the others issues, the two version of the text were no more aligned.

\item I also collect some general characteristics of the text, namely: the number of sentences, words and characters; the proportion of punctuation marks and capitalized letters; and the number of words per sentences.
\item POS tagging using \autocite{bird2009nltk} (I also consider
    using a \gls{crf} implementation \autocite[for instance][]{CRFsuite} but it
	require too much training for my goal). 23 minutes, simplified WSJ tag
\item One thing that I have not had time to consider is Named Entity Recognition. Yet it would have been interesting to see if this kind of information can provide some insight about personality. For instance, we may imagine that someone citing a lot of different places is more likely to be classified as opened to experience.
\item The last step was to go through all the texts to find all the distinct token along their count. A sample of that is shown in Table \vref{tab:dict}. Using this list, I process every text individually to compute its feature vector, that consist of:
	\begin{itemize}
		\item the five class label
		\item the six general characteristics
		\item the count of each of the 27 part of speech
		\item the count of each of the \numprint{29535} token
	\end{itemize}
		\begin{table}[hb]
			\centering
			\begin{tabular}{ccccccccccc}
				\toprule
				i & to & the & and & that & my & a & it & is & of & t \tabularnewline
				\midrule
				\numprint{123196} & \numprint{56649} & \numprint{40482} & \numprint{38078} & \numprint{31492} & \numprint{29831} & \numprint{29168} & \numprint{27563} & \numprint{25302} & \numprint{23179} & \numprint{20672}
				\tabularnewline
				\bottomrule
			\end{tabular}
			\caption{The first 11 of the \numprint{29535} unique tokens. As expected, most of them are stop words, expect for \emph{I}, which is explained by the nature of a stream of consciousness essays and \emph{t} which comes from negation's contraction, as the texts are written rather informally.}
			\label{tab:dict}
		\end{table}
\end{itemize}

\section{Classification}
Dimensionality reduction: \gls{svd}, LDA, \gls{ica}

Method: MN NB, RBF C-\gls{svm} (maybe with text kernel?), cosine \gls{knn}

Result tables

\section{Conclusion}
